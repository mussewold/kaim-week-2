{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Satisfaction Analysis\n",
    "\n",
    "This notebook analyzes customer satisfaction based on engagement and experience metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scripts.data_processing_utils import *\n",
    "from scripts.engagement_utils import *\n",
    "from scripts.experience_utils import *\n",
    "from scripts.satisfaction_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1 - Calculate Engagement and Experience Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_engagement_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m experience_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtcp_retransmission\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_rtt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_throughput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate engagement scores\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m engagement_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_engagement_scores\u001b[49m(\n\u001b[1;32m     14\u001b[0m     user_metrics, engagement_features, kmeans_engagement\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m user_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mengagement_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m engagement_scores\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate experience scores\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_engagement_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "df = load_and_preprocess_data()\n",
    "\n",
    "# Get engagement metrics\n",
    "user_metrics = aggregate_user_metrics(df)\n",
    "engagement_features = ['total_sessions', 'total_duration', 'total_volume']\n",
    "\n",
    "# Get experience metrics\n",
    "experience_metrics = aggregate_experience_metrics(df)\n",
    "experience_features = ['tcp_retransmission', 'avg_rtt', 'avg_throughput']\n",
    "\n",
    "# Calculate engagement scores\n",
    "engagement_scores = calculate_engagement_scores(\n",
    "    user_metrics, engagement_features, kmeans_engagement\n",
    ")\n",
    "user_metrics['engagement_score'] = engagement_scores\n",
    "\n",
    "# Calculate experience scores\n",
    "experience_scores = calculate_experience_scores(\n",
    "    experience_metrics, experience_features, kmeans_experience\n",
    ")\n",
    "experience_metrics['experience_score'] = experience_scores\n",
    "\n",
    "print(\"Sample of engagement scores:\")\n",
    "print(user_metrics[['engagement_score']].head())\n",
    "print(\"\\nSample of experience scores:\")\n",
    "print(experience_metrics[['experience_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2 - Calculate Satisfaction Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engagement_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Combine engagement and experience scores\u001b[39;00m\n\u001b[1;32m      2\u001b[0m satisfaction_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mengagement_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mengagement_scores\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperience_score\u001b[39m\u001b[38;5;124m'\u001b[39m: experience_scores\n\u001b[1;32m      5\u001b[0m }, index\u001b[38;5;241m=\u001b[39muser_metrics\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate satisfaction scores\u001b[39;00m\n\u001b[1;32m      8\u001b[0m satisfaction_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msatisfaction_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_satisfaction_scores(\n\u001b[1;32m      9\u001b[0m     satisfaction_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mengagement_score\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m     satisfaction_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperience_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engagement_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine engagement and experience scores\n",
    "satisfaction_df = pd.DataFrame({\n",
    "    'engagement_score': engagement_scores,\n",
    "    'experience_score': experience_scores\n",
    "}, index=user_metrics.index)\n",
    "\n",
    "# Calculate satisfaction scores\n",
    "satisfaction_df['satisfaction_score'] = calculate_satisfaction_scores(\n",
    "    satisfaction_df['engagement_score'],\n",
    "    satisfaction_df['experience_score']\n",
    ")\n",
    "\n",
    "# Get top 10 satisfied customers\n",
    "print(\"Top 10 Satisfied Customers:\")\n",
    "print(satisfaction_df.nlargest(10, 'satisfaction_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3 - Build Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for regression\n",
    "features = engagement_features + experience_features\n",
    "X = pd.concat([\n",
    "    user_metrics[engagement_features],\n",
    "    experience_metrics[experience_features]\n",
    "], axis=1)\n",
    "\n",
    "# Train model\n",
    "model, train_score, test_score, X_test, y_test = train_satisfaction_model(\n",
    "    X, satisfaction_df['satisfaction_score']\n",
    ")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot model performance\n",
    "plot_model_performance(y_test, y_pred)\n",
    "\n",
    "print(f\"Training R² score: {train_score:.4f}\")\n",
    "print(f\"Testing R² score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.4 - Satisfaction Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-means clustering on engagement and experience scores\n",
    "X = satisfaction_df[['engagement_score', 'experience_score']]\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "satisfaction_df['satisfaction_cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Plot clusters\n",
    "plot_satisfaction_clusters(satisfaction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.5 - Aggregate Scores by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores per cluster\n",
    "cluster_stats = satisfaction_df.groupby('satisfaction_cluster').agg({\n",
    "    'engagement_score': 'mean',\n",
    "    'experience_score': 'mean',\n",
    "    'satisfaction_score': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Average Scores by Cluster:\")\n",
    "print(cluster_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.6 - Export to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final table for export\n",
    "final_table = satisfaction_df.copy()\n",
    "final_table.index.name = 'user_id'\n",
    "\n",
    "# MySQL connection parameters\n",
    "connection_params = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'your_username',\n",
    "    'password': 'your_password',\n",
    "    'database': 'your_database',\n",
    "    'port': 3306\n",
    "}\n",
    "\n",
    "# Export to MySQL\n",
    "success = export_to_mysql(final_table, 'user_satisfaction', connection_params)\n",
    "\n",
    "if success:\n",
    "    print(\"Data successfully exported to MySQL\")\n",
    "else:\n",
    "    print(\"Failed to export data to MySQL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
